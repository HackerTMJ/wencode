# ğŸ§ª WenCode Testing Examples - Real Code

## How to Test: Complete Walkthrough

### Step 1: Install Dependencies
```powershell
cd "c:\Users\mjtan\Desktop\wencode"
pnpm install
# Downloads: typescript, vitest, eslint, prettier, etc.
# Creates: node_modules/ folders with all tools
```

### Step 2: Run Tests
```powershell
pnpm test
# Finds all .test.ts files
# Runs each test case
# Reports results
```

### Step 3: View Results
```
PASS  packages/core/src/tokenizer.test.ts

Tokenizer
  Basic tokens
    âœ“ should tokenize numbers (12ms)
    âœ“ should tokenize strings (5ms)
    âœ“ should tokenize identifiers (4ms)
  Chinese keywords
    âœ“ should recognize function keyword (3ms)
    ...more tests...
    
Test Files  1 passed (1)
Tests       32 passed (32)
Duration    125ms
```

---

## Real Test Examples (Copy-Paste Ready)

### Test 1: Basic Numbers
```typescript
// Input code to tokenize
const input = '123 456.78';

// What gets tokenized
const tokens = tokenize(input);
// Result: [
//   { type: 'NUMBER', value: '123', line: 1, column: 1 },
//   { type: 'NUMBER', value: '456.78', line: 1, column: 5 },
//   { type: 'EOF', value: undefined, line: 1, column: 12 }
// ]

// What the test checks
expect(tokens[0].type).toBe(TokenType.NUMBER);      âœ…
expect(tokens[0].value).toBe('123');                âœ…
expect(tokens[1].type).toBe(TokenType.NUMBER);      âœ…
expect(tokens[1].value).toBe('456.78');             âœ…
```

### Test 2: Chinese Function
```typescript
// Input: WenCode function declaration
const input = 'å‡½æ•° add(a, b) { è¿”å› a + b; }';

// What gets tokenized
const tokens = tokenize(input);
// Result includes:
// { type: 'FUNCTION', value: 'å‡½æ•°' }      â† Recognized!
// { type: 'IDENTIFIER', value: 'add' }
// { type: 'LPAREN', value: '(' }
// { type: 'IDENTIFIER', value: 'a' }
// { type: 'COMMA', value: ',' }
// { type: 'IDENTIFIER', value: 'b' }
// { type: 'RPAREN', value: ')' }
// { type: 'LBRACE', value: '{' }
// { type: 'RETURN', value: 'è¿”å›' }        â† Recognized!
// { type: 'IDENTIFIER', value: 'a' }
// { type: 'PLUS', value: '+' }
// { type: 'IDENTIFIER', value: 'b' }
// { type: 'SEMICOLON', value: ';' }
// { type: 'RBRACE', value: '}' }
// { type: 'EOF' }

// What the test checks
const tokenTypes = tokens.map(t => t.type);
expect(tokenTypes).toContain(TokenType.FUNCTION);   âœ…
expect(tokenTypes).toContain(TokenType.RETURN);     âœ…
expect(tokenTypes).toContain(TokenType.PLUS);       âœ…
```

### Test 3: Comments Removed
```typescript
// Input code with comment
const input = 'a // this is a comment\nb';

// What gets tokenized (comment removed)
const tokens = tokenize(input);
// Result: [
//   { type: 'IDENTIFIER', value: 'a' },
//   { type: 'IDENTIFIER', value: 'b' },
//   { type: 'EOF' }
// ]
// Total: 3 tokens (comment doesn't create token)

// What the test checks
expect(tokens.length).toBe(3);                      âœ…
expect(tokens[0].value).toBe('a');                  âœ…
expect(tokens[1].value).toBe('b');                  âœ…
// Comment is gone!
```

### Test 4: Position Tracking
```typescript
// Input with newline
const input = 'a b\nc';
//            line 1  line 2

// What gets tokenized
const tokens = tokenize(input);
// Result: [
//   { type: 'IDENTIFIER', value: 'a', line: 1, column: 1 },
//   { type: 'IDENTIFIER', value: 'b', line: 1, column: 3 },
//   { type: 'IDENTIFIER', value: 'c', line: 2, column: 1 },
//   { type: 'EOF' }
// ]

// What the test checks
expect(tokens[0].line).toBe(1);                     âœ…
expect(tokens[0].column).toBe(1);                   âœ…
expect(tokens[2].line).toBe(2);                     âœ…
expect(tokens[2].column).toBe(1);                   âœ…
// Position tracking works for error messages!
```

### Test 5: Operators
```typescript
// Input with multiple operators
const input = 'a + b - c * d / e % f ** g';
//            +   -   *   /   %   **

// What gets tokenized
const tokens = tokenize(input);
// Extracts each operator as separate token:
// IDENTIFIER, PLUS, IDENTIFIER, MINUS, IDENTIFIER, 
// MULTIPLY, IDENTIFIER, DIVIDE, IDENTIFIER, MODULO, 
// IDENTIFIER, POWER, IDENTIFIER, EOF

// What the test checks
expect(tokens[1].type).toBe(TokenType.PLUS);       âœ…
expect(tokens[3].type).toBe(TokenType.MINUS);      âœ…
expect(tokens[5].type).toBe(TokenType.MULTIPLY);   âœ…
expect(tokens[7].type).toBe(TokenType.DIVIDE);     âœ…
expect(tokens[9].type).toBe(TokenType.MODULO);     âœ…
expect(tokens[11].type).toBe(TokenType.POWER);     âœ…
```

### Test 6: Variables
```typescript
// Input: Variable declarations
const input = 'ä»¤ x = 10; å¸¸é‡ y = 20;';
//            LET   CONST

// What gets tokenized
const tokens = tokenize(input);
// Result includes:
// { type: 'LET', value: 'ä»¤' }               â† Chinese keyword
// { type: 'IDENTIFIER', value: 'x' }
// { type: 'ASSIGN', value: '=' }
// { type: 'NUMBER', value: '10' }
// { type: 'SEMICOLON', value: ';' }
// { type: 'CONST', value: 'å¸¸é‡' }           â† Chinese keyword
// ...rest...

// What the test checks
expect(tokens[0].type).toBe(TokenType.LET);        âœ…
expect(tokens[3].type).toBe(TokenType.NUMBER);     âœ…
expect(tokens[5].type).toBe(TokenType.CONST);      âœ…
```

### Test 7: Edge Case - Empty Input
```typescript
// Input: Empty string
const input = '';

// What gets tokenized
const tokens = tokenize(input);
// Result: [
//   { type: 'EOF' }
// ]
// Just EOF token, nothing else

// What the test checks
expect(tokens.length).toBe(1);                      âœ…
expect(tokens[0].type).toBe(TokenType.EOF);        âœ…
```

### Test 8: Hex Numbers
```typescript
// Input: Hexadecimal numbers
const input = '0xFF 0x123';
//            Hex  Hex

// What gets tokenized
const tokens = tokenize(input);
// Result: [
//   { type: 'NUMBER', value: '0xFF' },
//   { type: 'NUMBER', value: '0x123' },
//   { type: 'EOF' }
// ]

// What the test checks
expect(tokens[0].type).toBe(TokenType.NUMBER);     âœ…
expect(tokens[0].value).toBe('0xFF');              âœ…
expect(tokens[1].type).toBe(TokenType.NUMBER);     âœ…
expect(tokens[1].value).toBe('0x123');             âœ…
```

---

## Complete Test File Structure

```typescript
// packages/core/src/tokenizer.test.ts (197 lines)

import { describe, it, expect } from 'vitest';
import { Tokenizer, tokenize } from './tokenizer';
import { TokenType } from './token';

describe('Tokenizer', () => {
  // Group 1: Basic tokens
  describe('Basic tokens', () => {
    it('should tokenize numbers', () => {
      const tokens = tokenize('123 456.78');
      expect(tokens[0].type).toBe(TokenType.NUMBER);
      expect(tokens[0].value).toBe('123');
      expect(tokens[1].type).toBe(TokenType.NUMBER);
      expect(tokens[1].value).toBe('456.78');
    });
    
    // More tests...
  });
  
  // Group 2: Chinese keywords
  describe('Chinese keywords', () => {
    it('should recognize function keyword', () => {
      const tokens = tokenize('å‡½æ•° åå­—() {}');
      expect(tokens[0].type).toBe(TokenType.FUNCTION);
      expect(tokens[0].value).toBe('å‡½æ•°');
    });
    
    // More tests...
  });
  
  // ...more groups (32 tests total)
});
```

---

## Test Execution Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Run: pnpm test                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Vitest finds all .test.ts files      â”‚
â”‚    Found: tokenizer.test.ts             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Run first describe block             â”‚
â”‚    "Tokenizer"                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Run first nested describe            â”‚
â”‚    "Basic tokens" (3 tests)             â”‚
â”‚    - Test: numbers       âœ“              â”‚
â”‚    - Test: strings       âœ“              â”‚
â”‚    - Test: identifiers   âœ“              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Run next nested describe             â”‚
â”‚    "Chinese keywords" (4 tests)         â”‚
â”‚    - Test: function      âœ“              â”‚
â”‚    - Test: variables     âœ“              â”‚
â”‚    - Test: control flow  âœ“              â”‚
â”‚    - Test: loops         âœ“              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
           ... (continue for all 8 groups)
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Report Results:                         â”‚
â”‚ Test Files: 1 passed (1)                â”‚
â”‚ Tests: 32 passed (32)                   â”‚
â”‚ Duration: 125ms                         â”‚
â”‚                                         â”‚
â”‚ SUCCESS! âœ…                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Testing Checklist

- [ ] Run `pnpm install` successfully
- [ ] Run `pnpm test`
- [ ] See "32 passed (32)" in output
- [ ] See "0 failed"
- [ ] See "Test Files 1 passed (1)"
- [ ] All tests take < 200ms total
- [ ] Run `pnpm test -- --coverage`
- [ ] See coverage > 80%
- [ ] Run `pnpm type-check` (0 errors)
- [ ] Run `pnpm lint` (0 critical errors)
- [ ] Push to GitHub: `git push origin main`
- [ ] Check GitHub Actions: https://github.com/HackerTMJ/wencode/actions

---

## When npm Works - Execute This

```powershell
# Install dependencies
pnpm install

# Run tests
pnpm test

# If all pass (32/32), continue:
pnpm type-check
pnpm lint
pnpm build

# Commit success
git add .
git commit -m "feat: Phase 1.2 complete - tokenizer 100% tested"
git push origin main
```

**Current Status:** Ready to test! Just need npm to work.
