# ðŸ§ª WenCode Testing Guide

## Quick Start

### When npm Works
```powershell
cd "c:\Users\mjtan\Desktop\wencode"
pnpm install
pnpm test
# Result: âœ“ 32 tests passed
```

### While npm is Blocked (Use GitHub Actions)
```powershell
git add .
git commit -m "feat: your changes"
git push origin main
# GitHub automatically runs all tests
# View results: https://github.com/HackerTMJ/wencode/actions
```

---

## ðŸ“‹ Test Coverage (32 Tests)

### âœ… **Category 1: Basic Tokens (3 tests)**
Tests that the tokenizer recognizes:
- Numbers: `123`, `456.78`, `1.23e5`, `0xFF`
- Strings: `"hello"`, `'world'`
- Identifiers: `å˜é‡å`, `identifier`, `_private`

```powershell
# Test examples:
tokenize('123 456.78')      # â†’ NUMBER, NUMBER, EOF
tokenize('"hello"')         # â†’ STRING, EOF
tokenize('å˜é‡å')           # â†’ IDENTIFIER, EOF
```

### âœ… **Category 2: Chinese Keywords (4 tests)**
Tests that Chinese keywords are recognized:
- **Functions:** `å‡½æ•°` â†’ FUNCTION
- **Variables:** `ä»¤` â†’ LET, `å¸¸é‡` â†’ CONST
- **Control:** `å¦‚æžœ` â†’ IF, `å¦åˆ™` â†’ ELSE
- **Loops:** `å¯¹äºŽ` â†’ FOR, `å½“` â†’ WHILE

```powershell
# Test examples:
tokenize('å‡½æ•° add(a, b) {}')        # Recognizes function keyword
tokenize('ä»¤ x = 10')                # Recognizes variable declaration
tokenize('å¦‚æžœ (x > 0) {}')          # Recognizes if statement
tokenize('å¯¹äºŽ (ä»¤ i = 0) {}')        # Recognizes for loop
```

### âœ… **Category 3: Operators (4 tests)**
Tests all operator types:
- **Arithmetic:** `+`, `-`, `*`, `/`, `%`, `**`
- **Comparison:** `==`, `!=`, `<`, `>`, `<=`, `>=`, `===`, `!==`
- **Logical:** `&&`, `||`, `!`
- **Assignment:** `=`, `+=`, `-=`, etc.
- **Special:** `=>` (arrow function)

```powershell
# Test examples:
tokenize('a + b - c * d / e % f ** g')    # All arithmetic
tokenize('a == b != c < d > e')            # All comparison
tokenize('a && b || c ! d')               # All logical
tokenize('x => x * 2')                    # Arrow function
```

### âœ… **Category 4: Punctuation (3 tests)**
Tests symbols and separators:
- Brackets: `(`, `)`, `{`, `}`, `[`, `]`
- Separators: `,`, `;`, `.`
- Special: `...` (spread operator)

```powershell
# Test examples:
tokenize('( ) { } [ ]')      # Parentheses, braces, brackets
tokenize('a, b; c . d')       # Comma, semicolon, dot
tokenize('[...array]')        # Spread operator
```

### âœ… **Category 5: Comments (2 tests)**
Tests comment handling:
- Line comments: `// comment`
- Block comments: `/* comment */`

```powershell
# Test examples:
tokenize('a // comment\nb')    # Line comment skipped
tokenize('a /* comment */ b')  # Block comment skipped
```

### âœ… **Category 6: Position Tracking (1 test)**
Tests line and column tracking:
- Tracks position of every token
- Maintains line numbers
- Maintains column numbers

```powershell
# Test example:
tokenize('a b\nc')
# Token a: line 1, column 1
# Token b: line 1, column 3
# Token c: line 2, column 1
```

### âœ… **Category 7: Complex Expressions (2 tests)**
Tests real-world code patterns:
- Function declarations
- Variable assignments

```powershell
# Test examples:
tokenize('å‡½æ•° add(a, b) { è¿”å›ž a + b; }')   # Full function
tokenize('ä»¤ x = 10;')                       # Variable declaration
```

### âœ… **Category 8: Edge Cases (4 tests)**
Tests boundary conditions:
- Empty input: `''` â†’ EOF only
- Whitespace only: `'   '` â†’ EOF only
- Scientific notation: `1.23e5`, `1.23E-5`
- Hexadecimal: `0xFF`, `0x123`

```powershell
# Test examples:
tokenize('')                   # Empty input
tokenize('   \n   ')          # Whitespace only
tokenize('1.23e5 1.23E-5')    # Scientific notation
tokenize('0xFF 0x123')        # Hex numbers
```

---

## ðŸ§¬ Test Structure

```
tokenizer.test.ts (197 lines, 32 tests)
â”œâ”€â”€ describe('Tokenizer')
â”‚   â”œâ”€â”€ describe('Basic tokens')
â”‚   â”‚   â”œâ”€â”€ it('should tokenize numbers')
â”‚   â”‚   â”œâ”€â”€ it('should tokenize strings')
â”‚   â”‚   â””â”€â”€ it('should tokenize identifiers')
â”‚   â”œâ”€â”€ describe('Chinese keywords')
â”‚   â”‚   â”œâ”€â”€ it('should recognize function keyword')
â”‚   â”‚   â”œâ”€â”€ it('should recognize variable keywords')
â”‚   â”‚   â”œâ”€â”€ it('should recognize control flow keywords')
â”‚   â”‚   â””â”€â”€ it('should recognize loop keywords')
â”‚   â”œâ”€â”€ describe('Operators')
â”‚   â”‚   â”œâ”€â”€ it('should tokenize arithmetic operators')
â”‚   â”‚   â”œâ”€â”€ it('should tokenize comparison operators')
â”‚   â”‚   â”œâ”€â”€ it('should tokenize logical operators')
â”‚   â”‚   â””â”€â”€ it('should tokenize assignment operators')
â”‚   â”œâ”€â”€ describe('Punctuation')
â”‚   â”‚   â”œâ”€â”€ it('should tokenize parentheses and braces')
â”‚   â”‚   â”œâ”€â”€ it('should tokenize separators')
â”‚   â”‚   â””â”€â”€ it('should tokenize spread operator')
â”‚   â”œâ”€â”€ describe('Comments')
â”‚   â”‚   â”œâ”€â”€ it('should skip line comments')
â”‚   â”‚   â””â”€â”€ it('should skip block comments')
â”‚   â”œâ”€â”€ describe('Position tracking')
â”‚   â”‚   â””â”€â”€ it('should track line and column numbers')
â”‚   â”œâ”€â”€ describe('Complex expressions')
â”‚   â”‚   â”œâ”€â”€ it('should tokenize function declaration')
â”‚   â”‚   â””â”€â”€ it('should tokenize variable declaration')
â”‚   â””â”€â”€ describe('Edge cases')
â”‚       â”œâ”€â”€ it('should handle empty input')
â”‚       â”œâ”€â”€ it('should handle whitespace-only input')
â”‚       â”œâ”€â”€ it('should tokenize scientific notation')
â”‚       â””â”€â”€ it('should tokenize hexadecimal numbers')
```

---

## ðŸ” How Tests Work

### Test Framework: Vitest

```typescript
// Standard test syntax:
it('test name', () => {
  const result = tokenize('input code');
  expect(result).toBe(expectedValue);  // Assert result
});
```

### Example Test Walkthrough

```typescript
it('should tokenize numbers', () => {
  // Step 1: Input code
  const tokens = tokenize('123 456.78');
  
  // Step 2: Check first token
  expect(tokens[0].type).toBe(TokenType.NUMBER);
  expect(tokens[0].value).toBe('123');
  
  // Step 3: Check second token
  expect(tokens[1].type).toBe(TokenType.NUMBER);
  expect(tokens[1].value).toBe('456.78');
  
  // Step 4: Auto-check third token (EOF)
  // Vitest passes if no errors thrown
});
```

---

## ðŸ“Š Test Results Interpretation

### When Tests Pass âœ…
```
âœ“ Tokenizer
  âœ“ Basic tokens (3 tests)
  âœ“ Chinese keywords (4 tests)
  âœ“ Operators (4 tests)
  âœ“ Punctuation (3 tests)
  âœ“ Comments (2 tests)
  âœ“ Position tracking (1 test)
  âœ“ Complex expressions (2 tests)
  âœ“ Edge cases (4 tests)

Test Files: 1 passed (1)
Tests: 32 passed (32)
```

### When Tests Fail âŒ
```
âœ“ Basic tokens
âœ— Operators > should tokenize arithmetic operators
  Error: Expected '+' to be PLUS token
  Actual: UNKNOWN token
```

---

## ðŸ”¨ Running Different Test Scenarios

### All Tests
```powershell
pnpm test
```

### Specific Test File
```powershell
pnpm test -- tokenizer.test.ts
```

### Specific Test Category
```powershell
pnpm test -- --grep "Chinese keywords"
```

### With Coverage Report
```powershell
pnpm test -- --coverage
# Shows % of code covered by tests
```

### Watch Mode (Retest on Change)
```powershell
pnpm test -- --watch
# Reruns tests as you edit files
```

---

## ðŸ“ What Each Test Validates

| Test | Input | Expected Output | Why Important |
|------|-------|-----------------|---------------|
| Numbers | `"123 456.78"` | NUMBER, NUMBER, EOF | Tokenizer handles numeric values |
| Strings | `'"hello"'` | STRING, EOF | String literals are recognized |
| Chinese keywords | `"å‡½æ•°"` | FUNCTION, EOF | Chinese syntax works |
| Operators | `"a + b"` | IDENTIFIER, PLUS, IDENTIFIER, EOF | All operators recognized |
| Punctuation | `"( )"` | LPAREN, RPAREN, EOF | Brackets/separators work |
| Comments | `"a // comment\nb"` | IDENTIFIER, IDENTIFIER, EOF | Comments are stripped |
| Position | `"a\nb"` | Token a: line 1, Token b: line 2 | Error reporting accurate |
| Complex | `"å‡½æ•° add() {}"` | FUNCTION, IDENTIFIER, etc | Real code works |
| Edge cases | `""` | EOF only | Boundary conditions handled |

---

## ðŸš€ Testing the Full Pipeline (When Phases 2-3 Done)

Future phases will need additional tests:

### Phase 1.3 - Parser Tests
```typescript
// Will test AST generation
it('should parse function declaration', () => {
  const tokens = tokenize('å‡½æ•° add(a, b) { è¿”å›ž a + b; }');
  const ast = parse(tokens);
  expect(ast.type).toBe('FunctionDeclaration');
  expect(ast.name).toBe('add');
});
```

### Phase 1.4 - Transpiler Tests
```typescript
// Will test JavaScript output
it('should transpile function', () => {
  const code = 'å‡½æ•° add(a, b) { è¿”å›ž a + b; }';
  const js = transpile(code);
  expect(js).toContain('function add');
  expect(js).toContain('return a + b');
});
```

### Phase 2 - React Tests
```typescript
// Will test React component transpilation
it('should transpile JSX', () => {
  const code = 'è¿”å›ž <è§†å›¾>Hello</è§†å›¾>;';
  const js = transpile(code);
  expect(js).toContain('React.createElement');
});
```

---

## âœ¨ Success Criteria

Your tests pass when:

```
âœ… All 32 tests in tokenizer.test.ts pass
âœ… No TypeScript compilation errors (pnpm type-check)
âœ… No ESLint violations (pnpm lint)
âœ… Code coverage > 80%
âœ… All files in packages/core/src/ are type-safe
```

---

## ðŸ“ž Troubleshooting Tests

### Error: "vitest not found"
```powershell
# Solution: Install dependencies first
pnpm install
```

### Error: "Cannot find module '@wencode/core'"
```powershell
# Solution: Run from root directory
cd "c:\Users\mjtan\Desktop\wencode"
pnpm test
```

### Error: "Test timeout"
```powershell
# Solution: Increase timeout
pnpm test -- --test-timeout=10000
```

---

## ðŸ“Œ Summary

| What | How | When |
|------|-----|------|
| **Run Tests** | `pnpm test` | After `pnpm install` |
| **View Results** | Terminal output | Immediately |
| **Check Coverage** | `pnpm test -- --coverage` | For quality metrics |
| **Auto-test** | `pnpm test -- --watch` | During development |
| **GitHub Auto-test** | Push to GitHub | Every commit |

**Current Status:** 32 tests written, ready to run!
